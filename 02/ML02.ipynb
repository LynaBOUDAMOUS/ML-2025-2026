{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import binom "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "# Génération des données\n",
    "\n",
    "Fonction $x\\mapsto \\cos(10 x) e^{-x}$ avec un bruit Gaussien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Echantillon:\n",
    "    def __init__(self, gauche, droite, bruit, taille_echantillon):\n",
    "        self.gauche = gauche \n",
    "        self.droite = droite\n",
    "        self.bruit = bruit \n",
    "        self.taille_echantillon = taille_echantillon\n",
    "        self.xs = np.linspace(gauche, droite, taille_echantillon)\n",
    "        self.ys = self.inconnue(self.xs) + bruit * np.random.randn(taille_echantillon)\n",
    "\n",
    "    def inconnue(self, x):\n",
    "        return np.cos(10 * x) * np.exp(-x)\n",
    "\n",
    "    def visualisation(self, rep):\n",
    "        xs = np.linspace(self.gauche, self.droite, 200)\n",
    "        ys = self.inconnue(xs)\n",
    "        rep.plot(xs, ys, color=\"blue\", label=\"inconnue\")\n",
    "        rep.scatter(self.xs, self.ys, color=\"red\", label=\"echantillon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech20 = Echantillon(gauche=0., droite=2., bruit=0.1, taille_echantillon=20)\n",
    "_, rep = plt.subplots()\n",
    "ech20.visualisation(rep)\n",
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {},
   "source": [
    "# Apprentissage\n",
    "\n",
    "On va approcher l'échantillon en\n",
    "\n",
    "- minimisant l'erreur quadratique moyenne\n",
    "- avec les polynomes de degrés inférieur à $d$\n",
    "- en utilisant la base de Bernstein sur l'intervalle $[a,b]$\n",
    "\n",
    "$$\n",
    "J_2(P) = \\frac{1}{N} \\sum_{i=1}^N (y_i - P(x_i))^2.\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(X) = \\sum_{k=0}^d c_k \\binom{d}{k} \\left(\\frac{X - a}{b-a}\\right)^k \\left(1 - \\frac{X - a}{b-a}\\right)^{d-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bernstein:\n",
    "    def __init__(self, degres, a, b):\n",
    "        self.a = a \n",
    "        self.b = b\n",
    "        self.degres = degres\n",
    "        self.coefficients = np.zeros(degres + 1)\n",
    "\n",
    "    def predict(self, xs):\n",
    "        resultat = np.zeros_like(xs)\n",
    "        variable = (xs - self.a) / (self.b - self.a)\n",
    "        for (k, c) in enumerate(self.coefficients):\n",
    "            resultat = (\n",
    "                resultat \n",
    "                + c \n",
    "                * binom(self.degres, k) \n",
    "                * np.power(variable, k) \n",
    "                * np.power(1. - variable, self.degres - k)\n",
    "            )\n",
    "        return resultat\n",
    "\n",
    "    def fit(self, xs, ys):\n",
    "        def a_minimiser(coefficients):\n",
    "            self.coefficients = coefficients\n",
    "            return self.erreur(xs, ys)\n",
    "\n",
    "        resultat = minimize(a_minimiser, self.coefficients)\n",
    "        if not resultat.success:\n",
    "            print(resultat)\n",
    "        self.coefficients = resultat.x\n",
    "\n",
    "    def erreur(self, xs, ys):\n",
    "        return np.mean((self.predict(xs) - ys) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**EXERCICE** visualiser les polynomes de Bernstein de degrés $2$ de coefficients\n",
    "\n",
    "- $(1, 0, 0)$\n",
    "- $(0, 1, 0)$\n",
    "- $(0, 0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de predict\n",
    "_P001 = Bernstein(degres=2, a=0, b=2)\n",
    "_P001.coefficients = np.array((0, 0, 1))\n",
    "_P100 = Bernstein(degres=2, a=0, b=2)\n",
    "_P100.coefficients = np.array((1, 0, 0))\n",
    "_P010 = Bernstein(degres=2, a=0, b=2)\n",
    "_P010.coefficients = np.array((0, 1, 0))\n",
    "\n",
    "_xs = np.linspace(0, 2, 200)\n",
    "plt.plot(_xs, _P001.predict(_xs))\n",
    "plt.plot(_xs, _P010.predict(_xs))\n",
    "plt.plot(_xs, _P100.predict(_xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience(degres, echantillon):\n",
    "    P2 = Bernstein(degres, a=0, b=2)\n",
    "    P2.fit(echantillon.xs, echantillon.ys)\n",
    "\n",
    "    _, rep = plt.subplots()\n",
    "    rep.set_title(f\"d={degres}\")\n",
    "    echantillon.visualisation(rep)\n",
    "    xs = np.linspace(echantillon.gauche, echantillon.droite, 200)\n",
    "    rep.plot(xs, P2.predict(xs), color=\"cyan\", label=\"prédicteur\")\n",
    "    rep.legend()\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**EXERCICE** Expérimenter avec des degrés plus élevés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience(degres=2, echantillon=ech20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience(degres=5, echantillon=ech20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience(degres=7, echantillon=ech20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience(degres=10, echantillon=ech20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience(degres=15, echantillon=ech20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience(degres=20, echantillon=ech20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Méthodologie\n",
    "\n",
    "Dans la situation présente on connait l'échantillon (points rouges) et la fonction inconnue.\n",
    "On peut donc juger de l'adéquation à l'échantillon mais aussi de la capacité du modèle à généraliser.\n",
    "\n",
    "Dans la pratique, on aura que l'échantillon.\n",
    "Comment peut-on juger de la capacité du modèle à généraliser?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**EXERCICE** Ajouter une possibilité dans la classe échantillon de générer les abcisses en utilisant la loi uniforme plutot qu'en découpant régulièrement l'intervalle.\n",
    "Reprendre alors l'expérience ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchantillonV2:\n",
    "    def __init__(self, gauche, droite, bruit, taille_echantillon, aleatoire=False):\n",
    "        self.gauche = gauche \n",
    "        self.droite = droite\n",
    "        self.bruit = bruit \n",
    "        self.taille_echantillon = taille_echantillon\n",
    "        if aleatoire:\n",
    "            self.xs = np.random.uniform(low=self.gauche, high=self.droite, size=(self.taille_echantillon,))\n",
    "        else:\n",
    "            self.xs = np.linspace(gauche, droite, taille_echantillon)\n",
    "        self.ys = self.inconnue(self.xs) + bruit * np.random.randn(taille_echantillon)\n",
    "\n",
    "    def inconnue(self, x):\n",
    "        return np.cos(10 * x) * np.exp(-x)\n",
    "\n",
    "    def visualisation(self, rep=None, couleur=None):\n",
    "        if couleur is None:\n",
    "            couleur=\"red\"\n",
    "        if rep is None:\n",
    "            _, rep = plt.subplots()\n",
    "        xs = np.linspace(self.gauche, self.droite, 200)\n",
    "        ys = self.inconnue(xs)\n",
    "        rep.plot(xs, ys, color=\"blue\", label=\"inconnue\")\n",
    "        rep.scatter(self.xs, self.ys, color=couleur, label=\"echantillon\")\n",
    "        return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech30 = EchantillonV2(gauche=0., droite=2., bruit=0.1, taille_echantillon=30, aleatoire=True)\n",
    "ech30.visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience(degres=10, echantillon=ech30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pvdt",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**REMARQUE** On voit que la capacité du modèle à généraliser dans les zones où il y a peu de points rouges est limité.\n",
    "On va donc séparer l'échantillon en deux\n",
    "\n",
    "1. Une partie servira encore à l'entrainement\n",
    "2. Une autre partie sera laissée de coté pendant l'entrainement et permettra de tester la capacité à généraliser\n",
    "\n",
    "On appelle cette méthode un `train_test_split`.\n",
    "\n",
    "**EXERCICE** Coder une fonction `train_test_split` prenant en entrée un échantillon et le découpant en deux de manière aléatoire suivant une certaine proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    echantillon: EchantillonV2, \n",
    "    proportion: float = 0.7\n",
    ") -> tuple[EchantillonV2, EchantillonV2]:\n",
    "    if proportion < 0 or proportion > 1:\n",
    "        raise ValueError(\"Proportion doit etre entre 0 et 1\")\n",
    "    x_tr, y_tr, x_te, y_te = [], [], [], []\n",
    "    for x, y in zip(echantillon.xs, echantillon.ys):\n",
    "        if np.random.rand() < proportion:\n",
    "            x_tr.append(x)\n",
    "            y_tr.append(y)\n",
    "        else:\n",
    "            x_te.append(x)\n",
    "            y_te.append(y)\n",
    "\n",
    "    ech_tr = EchantillonV2(\n",
    "        gauche=echantillon.gauche,\n",
    "        droite=echantillon.droite, \n",
    "        bruit=echantillon.bruit, \n",
    "        taille_echantillon=len(x_tr),\n",
    "    )\n",
    "    ech_tr.xs = np.array(x_tr)\n",
    "    ech_tr.ys = np.array(y_tr)\n",
    "    ech_te = EchantillonV2(\n",
    "        gauche=echantillon.gauche,\n",
    "        droite=echantillon.droite, \n",
    "        bruit=echantillon.bruit, \n",
    "        taille_echantillon=len(x_te),\n",
    "    )\n",
    "    ech_te.xs = np.array(x_te)\n",
    "    ech_te.ys = np.array(y_te)\n",
    "    return ech_tr, ech_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech30_tr, ech30_te = train_test_split(echantillon=ech30, proportion=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHfw",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rep = ech30_tr.visualisation(couleur=\"red\")\n",
    "ech30_te.visualisation(rep=_rep, couleur=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xXTn",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "**EXERCICE** Afficher les courbes d'erreur de la partie training et de la partie test en fonction du degrés du modèle utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjVT",
   "metadata": {},
   "outputs": [],
   "source": [
    "def courbes_erreurs(ech_tr, ech_te, dmax):\n",
    "    erreurs_tr, erreurs_te = [], []\n",
    "    for d in range(2, dmax+1):\n",
    "        bern = Bernstein(a=ech_tr.gauche, b=ech_tr.droite, degres=d)\n",
    "        bern.fit(ech_tr.xs, ech_tr.ys)\n",
    "        erreurs_tr.append(bern.erreur(ech_tr.xs, ech_tr.ys))\n",
    "        erreurs_te.append(bern.erreur(ech_te.xs, ech_te.ys))\n",
    "\n",
    "    _, rep = plt.subplots()\n",
    "    rep.set_title(f\"N={ech_tr.taille_echantillon}\")\n",
    "    rep.set_xlabel(\"degre du polynome\")\n",
    "    rep.semilogy(range(2, dmax+1), erreurs_tr, label=\"entrainement\")\n",
    "    rep.semilogy(range(2, dmax+1), erreurs_te, label=\"test\")\n",
    "    rep.legend()\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pHFh",
   "metadata": {},
   "outputs": [],
   "source": [
    "courbes_erreurs(ech_te=ech30_te, ech_tr=ech30_tr, dmax=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NCOB",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech60 = EchantillonV2(gauche=0., droite=2., bruit=0.1, taille_echantillon=60, aleatoire=True)\n",
    "ech60_tr, ech60_te = train_test_split(echantillon=ech60, proportion=0.7)\n",
    "_rep = ech60_tr.visualisation(couleur=\"red\")\n",
    "ech60_te.visualisation(rep=_rep, couleur=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aqbW",
   "metadata": {},
   "outputs": [],
   "source": [
    "courbes_erreurs(ech_te=ech60_te, ech_tr=ech60_tr, dmax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TRpd",
   "metadata": {},
   "source": [
    "**CONCLUSION** On voit qu'au début les deux erreurs diminuent lorsque la complexité du modèle augmente.\n",
    "Par contre, il finit par se passer un décrochage entre l'erreur d'entrainement qui continue à diminuer et celle de test qui augmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXez",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

